from .Explainer import Explainer
import logging
from utilities import ExplanationType, ExplanationScope
import pandas as pd

from aix360.algorithms.rbm import BooleanRuleCG, BRCGExplainer, FeatureBinarizer

logger = logging.getLogger(__name__)


class BooleanRuleCGExplainer:
    """
    An explainer that leverages the BooleanRuleCG model from AIX360 to generate interpretable
    boolean rules for classification problems. This explainer is designed to work with datasets
    processed for text classification, using vectorized features (`X_vectorized`) and predicted
    labels (`y_predicted`). It fits a BooleanRuleCG model to the provided dataset and can return
    a specified number of rules that the model uses to make predictions, offering insights into
    the decision-making process.
    """

    def __init__(self, dataset, **kwargs):
        """
        Initializes the BooleanRuleCGExplainer with a dataset.

        Parameters:
            dataset: An object containing the dataset used for training the model. It must
                     have `X_vectorized` (pandas.DataFrame or similar structure) as the input
                     features for the model and `y_predicted` (pandas.Series or similar structure)
                     as the target labels.
            **kwargs: Additional keyword arguments for further customization.
        """
        super().__init__(**kwargs)
        self.dataset = dataset
        self.scope = ExplanationScope.GLOBAL
        self.explanation_type = ExplanationType.RULE
        fb = FeatureBinarizer(negations=True)
        X_train_fb = fb.fit_transform(pd.DataFrame(
            self.dataset.X_vectorized.toarray(), columns=self.dataset.feature_names))
        self.explainer = BRCGExplainer(BooleanRuleCG())
        self.explainer.fit(X_train_fb, self.dataset.y_predicted)

    def __call__(self, n_rules=None):
        """
        Generates and returns a list of interpretable rules derived from the fitted
        BooleanRuleCG model. These rules provide insight into the model's decision-making
        process by highlighting conditions under which certain predictions are made.

        Parameters:
            n_rules (int, optional): The number of top rules to return. If None, all rules
                                     generated by the model are returned. Note that the notion
                                     of 'top' rules is based on the order provided by the BooleanRuleCG
                                     model, as it does not explicitly rank rules by importance.

        Returns:
            list of str: A list containing the rules. Each rule is represented as a string
                         that describes a condition leading to a specific prediction.
        """
        # Get the model explanation/rules
        explanation = self.model.explain()
        rules = explanation.split('\n')

        # If n_rules is specified and less than the total number of rules, return the top n_rules
        if n_rules is not None and len(rules) > n_rules:
            return rules[:n_rules]
        return rules
